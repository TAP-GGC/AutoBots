<!-- height or width of logo may be adjusted -->
<!-- This section is where you will replace the link to your transparent logo, the title of your project, and the very short desciptor of your project -->
<!-- If you used Canva to make your icon and don't want to pay for a background remover, you can use the website https://www.remove.bg/ to do so -->
<p align="center">
  <img alt="Autbots Logo" src="media/logos/3dcnn.png" width="" height="350" />
  <h1 align="center">A simulation of Convolutional Neural Network for Self-Driving Cars</h1>
  <p align="center">A project for all ages with an interest in Artificial Intelligence by team Autobots </p>
</p>
<!-- the emojis are not set in stone! If you'd like you can remove them entirely or select your own from https://gist.github.com/rxaviers/7360908 you are welcome to -->

## :loudspeaker: About
AutoBots is a maze puzzle where students get to learn how image recognition works with robots and how
proper data training is essential for robots to recognize images.
<!-- You can look at other TAP projects if you need a better idea of how to describe your workshops objectives -->

This workshop has participants train their own Convolutional Neural Network to recognize custom hand gestures and allow control of a Makeblock Mbot Mega. Students get to create their own distinct dataset based on images captured of their hand. The robot would then navigate through some obstacles and each gesture would reflect how well the robot could recognize those images.

## :bulb: Project Information
<!-- 
Your Options for target audience: 
  - High School
  - College
  - Middle School
  - K-12
  - Non-Stem
  - Undergraduate
You can select from a range of audiences or a single auidience. Examples: 
    Middle School - College 
    High School - College
    K-12
  You will be presenting most often to your peers who are taking introductory technology classes, so more often than not you should be including college in your target audience range. 
-->
* <b>Difficulty Level:</b> Intermediate
* <b>Target Audience:</b> 6-12, College, Non-Stem
* <b>Duration of Workshop:</b> 1 hour
* <b>Needed Materials:</b> Mbot Mega, Google Chrome web--browser, Laptop with camera
* <b>Learning Outcomes:</b> The primary goal is to show the audience how distinct training datasets can effect how well a neural network can recognize images. Specifications such as lighting and angle of the image can impact the accuracy of the model.
* <b>Your Main Technology</b> MBlock (Uses Scratch Block Coding)
* [Technology Ambassador Program](https://tapggc.org/) <b>(TAP)</b> is a project-based class that provides a collaborative environment for students to work with their fellow classmates on a semester-long project using technologies of their choice. TAP strives to increase participation in IT through numerous outreach activities and workshops that are designed to showcase the creative and fun side of technology.
<!-- Commercial Video stored in the Media folder will be linked here -->


https://github.com/user-attachments/assets/bf293176-6c56-42a5-abb3-8fcd7001cc5e


<!-- videos can also be dragged and dropped into markdown files if you want them embedded -->

## :pencil2: Team: Autobots

<!-- Use the team photo of your choice once youve uploaded it to the team photo folder within the media folder -->
<img alt="art featuring batman, wonder woman, and superman" src = "media/team photos/teamautobots.jpg" width="" height="300">

> (From left to right: Jonathan, Krishan, and Isaiah)
<!-- replace with full names of your team members -->

* Jonathan Tran
* Krishan Bhalsod
* Isaiah Gorman
  

## :mortar_board: Advisors
<!-- name of the two professors overseeing your TAP class -->
* Dr. Cengiz Gunay
* Dr. Cindy Robertson


## :page_with_curl: Project Description
In this project, students will design custom hand gestures or images to represent specific movements or commands for an MBot robot. Using image recognition and machine learning, students will train a model to recognize these gestures and teach the robot to react accordingly—whether it’s moving forward, turning, stopping to navigating obstacles. This hands-on project will allow students to develop their skills in image recognition, AI model training, and robotics control, while exploring the complexities and challenges of creating real-world applications using AI and robotics technologies.


## :memo: Publications
<!-- team members, then professors/advisors. "Name of Publication", event, month and day, year, Georgia Gwinnett College. -->

1. R. Yamashita, M. Nishio, R. K. G. Do, and K. Togashi, “Convolutional neural networks: an overview and application in radiology.,” Insights Imaging, vol. 9, no. 4, pp. 611–629, Aug. 2018, doi: 10.1007/s13244-018-0639-9.
2. Tapia Abstract - Bhalsod, K., Gorman, I., Tran, J., Gunay, C., & Robertson, C. (2025, April 11). Learning Convolutional Neural Networks Using mBots.
3. STARS and CREATE Symposium - Bhalsod, K., Gorman, I., Tran, J., Gunay, C., & Robertson, C. (2025, April 11). Controlling Robots Using Image Recognition. 

## :open_hands: Outreach
<i>List the outreach events your team has participated in. </i>

1. <b>Atlanta Science Festival</b> March 15, 2025, Georgia Gwinnett College: Promote IT field and teach Convolutional Neural Networks to those interested.
2. <b>Atlanta Science Festival</b> March 22, 2025, Piedmont Park (Atlanta): Promote IT field and teach Convolutional Neural Networks to those interested.
3. <b>Class Workshops</b> March 31 & April 1 & 4, 2025, Georgia Gwinnett College: Promote IT field and teach Convolutional Neural Networks to those interested.

## :mag_right: Similar Projects
### AI Projects
* [AiDiva](https://github.com/TAP-GGC/AiDiva)
* [ArtifyAI](https://github.com/TAP-GGC/ArtifyAI)
### Robot Projects
* [Jedi](https://github.com/TAP-GGC/Jedi) (Sphero)
* [Ballislife](https://github.com/TAP-GGC/ball-is-life) (Sphero)
* [DancingSphero](https://github.com/TAP-GGC/DancingSphero) (Sphero)
* [Code-Inator](https://github.com/TAP-GGC/Code-Nator) (MBot)
* [Wanda](https://github.com/TAP-GGC/wanda) (Cosomo)
* [TechGoldFish](https://github.com/TAP-GGC/TechGoldFish) (Sphero)
* [Dronereality](https://github.com/TAP-GGC/dronereality) (Drones)

If you're interested in more workshops that utilize Scratch, check out [Space Mechanic](https://github.com/TAP-GGC/NinjaTurtles)!

## :computer: Technology
<!-- be sure to use the alt text feature in case anybody viewing your repo is using  screen reader! you want your workshop to be as accessible as possible -->
<p align="center">
  <img alt="MBlock Logo" src = "media/technology/mbotlogo.png" width="200" height="200"/>
</p>

* [MBlock](https://mblock.cc/) is a block-based programming languaged used to teach kids and beginners about coding. It's based off the Scratch 3.0 interface.
* Because of it being based off Scratch, beginners don't need to worry about coding due its drag-and-drop interface. The mBlock software contains a plethora of extentions and it allows support for AI.
* Autobots uses MBlock, which is a Scratch program that comes along with the MBot. While MBlock is Scratch-based, it also contain Google's teachable machine, which helps train the MBot in image recognition.

<p align="center">
<img src = "media/technology/block-based language.png" width ="400" height="200">
</p>

## Project Setup/Installation 

[Building the mBot Mega Instructions](https://support.makeblock.com/hc/en-us/articles/1500009896321-Build-mBot-Mega)

<!-- if your project uses scratch, you can reuse any of these instructions (be sure to include CS First alternatives) -->
## MBot connection to MBlock
1. Click on the link here: https://planet.mblock.cc/project/5574657
2. Turn on MBot
3. Scroll down and click source code
4. On the device tab, select bluetooth, enable bluetooth if prompted, and connect.
5. If done right, the blue light within the MBot will stop blinking.
   
[Click here to view instructions](/documents/tutorial%20materials/mbotconnect.md)

## Usage
<i> Post connection to the MBot with MBlock open with the correct link. WEBCAM AND GOOGLE CHROME IS REQUIRED. </i> 
1. On the sprite tab, scroll down from the open bar where all code blocks are stored.
2. If done correctly, there is a block for teachable machine. Click on it.
3. On top of the block codes, there is a Create/Manage model. Click on it.
4. Scroll down and select Image Recognition (or alike).
5. Ensure that webcam is enabled/turned on. Create desired amount of classes.
6. Using the webcam, take a single or multiple pictures of your desired object. In this case, hands would be the object.
7. Do this for all classes. Ensure that each object is distinct from each other.
8. When finished, change model settings to your desired preference. For this project, keep settings default. Click on train model.
9. When finished, webcam should turn on. Test your objects to ensure right classes are being identified.
10. If correct, click on the top left to use model.
11. While on the sprite tab, replace all instances of model name and classes to your model/class naming convention.
12. Run code to test if models and classes are working. If it is not working, check if all instances are correctly placed (i.e. Stop function is replaced with Stop class equivalent). Otherwise, you just made your first Convolutional Neural Network model!

## Workshop Instructions 
[Workshop Video on how to control your mBot](https://youtu.be/nPc_onJ8ggs)

[Click here to view workshop walkthrough PDF file](/documents/tutorial%20materials/Workshop%20PDF.pdf)


## Demo Video
[Our Demo Video](https://youtu.be/oV6r2fmOg98)

